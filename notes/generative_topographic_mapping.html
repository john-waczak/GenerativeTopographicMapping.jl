<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="John Waczak">
<meta name="dcterms.date" content="2023-01-27">

<title>Generative Topographic Mapping</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="generative_topographic_mapping_files/libs/clipboard/clipboard.min.js"></script>
<script src="generative_topographic_mapping_files/libs/quarto-html/quarto.js"></script>
<script src="generative_topographic_mapping_files/libs/quarto-html/popper.min.js"></script>
<script src="generative_topographic_mapping_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="generative_topographic_mapping_files/libs/quarto-html/anchor.min.js"></script>
<link href="generative_topographic_mapping_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="generative_topographic_mapping_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="generative_topographic_mapping_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="generative_topographic_mapping_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="generative_topographic_mapping_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Generative Topographic Mapping</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>John Waczak </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 27, 2023</p>
    </div>
  </div>
    
  </div>
  

</header>

<section id="introduction" class="level1">
<h1>Introduction</h1>
<p><em>Goal</em>: We want models that can find interesting structures in un-structured data without the need for human labeling or intervention. The key feature of many such methods is that they perform <strong>Dimensionality reduction</strong>. Data in some high dimensional feature space are <em>assumed</em> to truly be living on a lower dimensional submanifold of the higher dimensional space. If the goal is to visualize interesting structures in the data, typically, we chose the dimension of the reduced data to be <span class="math inline">2</span>, or <span class="math inline">3</span>.</p>
<p><strong>Generative Topographic Mapping</strong> assumes that our large dimensional dataset <span class="math inline">\mathcal{D}\subseteq \mathbb{R}^D</span> is actually <em>generated</em> by a set of <strong>latent variables</strong> living in <span class="math inline">\mathbb{R}^L</span>. For visualization, we will typically choose <span class="math inline">L=2</span>, but strictly speaking, we require only that <span class="math inline">L&lt;D</span>. Our goal then is to learn the mapping from latent variables to our data space.</p>
<section id="notation" class="level2">
<h2 class="anchored" data-anchor-id="notation">Notation:</h2>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Notation</th>
<th>Description</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\mathbf{x}\in\mathbb{R}^L</span></td>
<td>Latent vector</td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\mathbf{t}_n \in \mathbb{R}^D</span></td>
<td>Data vector</td>
<td><span class="math inline">n=1,..., N</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\mathbf{y}=\mathbf{y}(\mathbf{x};w)</span></td>
<td>latent vector transformation</td>
<td><span class="math inline">\mathbf{y}:\mathbb{R}^L\mapsto\mathbb{R}^D</span></td>
</tr>
<tr class="even">
<td><span class="math inline">w</span></td>
<td>vector/matrix of weights for the mapping transformation</td>
<td></td>
</tr>
</tbody>
</table>
<p>The <strong>GTM</strong> is a principled expansion of both <em>Factor Analysis</em> (the linear latent variable model) and the <em>Self Organizing Map</em> (aka Kohonen Maps).</p>
<p>To expand the capabilities of <em>factor analysis</em> to consider nonlinear transformations of latent vectors, we consider the underlying distribution <span class="math display">\begin{equation}
    p(\mathbf{t}\vert \mathbf{x},w,\beta) := \mathcal{N}(\mathbf{y}(\mathbf{x};w), \frac{1}{\beta})
\end{equation}</span> i.e.&nbsp;the embedded (transformed) latent vectors are normally distributed with mean given by <span class="math inline">\mathbf{y}</span> and covariance <span class="math inline">\beta^{-1}</span>. Provided we have some knowledge of the distribution of latent vectors <span class="math inline">p(\mathbf{x})</span> (aka the Bayesian prior), we can then integrate to obtain</p>
<p><span class="math display">\begin{equation}
    p(\mathbf{t}\vert w, \beta) = \int d\mathbf{x}; p(\mathbf{t}\vert \mathbf{x},w,\beta)p(\mathbf{x})
\end{equation}</span></p>
<p>This is what we really want: the distribution of our embedded data <span class="math inline">\mathbf{t}</span> given the parameters of our model <span class="math inline">w</span> and <span class="math inline">\beta</span>. Unfortunately, this integral is not tractible without a <em>nice</em> model for <span class="math inline">p(\mathbf{x})</span>. We therefore take inspiration from the <em>Self Organizing Map</em> which models latent vectors as the nodes of a topologically connected mesh. Thus, we form</p>
<p><span class="math display">\begin{equation}
    p(\mathbf{x}) := \frac{1}{K}\sum_k^K \delta(\mathbf{x}-\mathbf{x}_k)
\end{equation}</span></p>
<p>In words: the latent dataspace is described by <span class="math inline">K</span> vectors <span class="math inline">\mathbf{x}_k</span> which lie preciesly on the nodes of a regular mesh. For any latent vector <span class="math inline">\mathbf{x}</span>, there is a probability of <span class="math inline">1/K</span> that it <em>came from</em> the <span class="math inline">k^{th}</span> vector <span class="math inline">\mathbf{x}_k</span>.</p>
<p>As mathematicians (or physicists, or data scientists, etc‚Ä¶) we rejoice at the site of the Dirac-<span class="math inline">\delta</span> functions which greatly simplify our integration. Our embedded data distribution now becomes: <span class="math display">\begin{align}
    p(\mathbf{t}\vert w,\beta) &amp;= \int d\mathbf{x}\; p(\mathbf{t}\vert \mathbf{x}, w, \beta) \frac{1}{K}\sum_k^K \delta(\mathbf{x}-\mathbf{x}_k) \\
    &amp;= \frac{1}{K}\sum_k^K p(\mathbf{t}\vert \mathbf{x}_k, w, \beta)
\end{align}</span> which is <em>much</em>, <em>much</em> nicer to deal with.</p>
<p>The question now becomes the following: provided a dataset <span class="math inline">\mathcal{D}=\{\mathbf{t}_1, ..., \mathbf{t}_N \}</span>, what are the best parameters <span class="math inline">w</span> and <span class="math inline">\beta</span> to fit our latent variable model? Assuming each of the <span class="math inline">\mathbf{t}_i</span> are independent and indetically distributed, we can write the <em>likelihood</em> (odds of obtaining parameters <span class="math inline">w</span> and <span class="math inline">\beta</span> given the dataset <span class="math inline">\mathcal{D}</span>) as <span class="math display">\begin{align}
    \mathcal{L}(w,\beta) &amp;:= \prod_n^N p(\mathbf{t}_n\vert w, \beta) \\
    &amp;= \prod_n^N \left[ \frac{1}{K}\sum_k^K p(\mathbf{t}_n\vert \mathbf{x}_k, w, \beta) \right]
\end{align}</span></p>
<p>Sums are easier to manipulate than products and so we make the strategic choice to instead work with the <em>log-likelihood</em> function <span class="math inline">\ell(w,\beta)=\log(\mathcal{L}(w,\beta))</span></p>
<p><span class="math display">\begin{equation}
    \ell(w, \beta) = \sum_n^N \ln\left\{ \frac{1}{K}\sum_k^K p(\mathbf{t}_n\vert \mathbf{x}_k, w, \beta) \right\}
\end{equation}</span></p>
<p>We now have an optimization problem! Our goal is to find those <span class="math inline">w</span> and <span class="math inline">\beta</span> which maximize the likelihood of obtaining our dataset <span class="math inline">\mathcal{D}=\{\mathbf{t}_1, ... , \mathbf{t}_N\}</span> from the latent vectors <span class="math inline">\mathbf{x}_k</span> living on the regular SOM-like grid.</p>
</section>
<section id="summary-so-far" class="level2">
<h2 class="anchored" data-anchor-id="summary-so-far">Summary so far</h2>
<ul>
<li>We treat our data as points, <span class="math inline">\mathbf{t}</span>, living in living in a manifold <span class="math inline">\mathcal{D}</span> which is embedded in some high dimensional space <span class="math inline">\mathbb{R}^D</span>.</li>
<li>We assume our data is Normally distributed in this high dimensional space with mean <span class="math inline">\mathbf{y}(\mathbf{x};w)</span> and covariance <span class="math inline">\beta^{-1}</span></li>
<li>Each of our data points actually <strong>comes from</strong> a lower dimensional latent space of points <span class="math inline">\mathbf{x}</span>.</li>
<li>These lower dimensional points are then mapped by a nonlinear function <span class="math inline">\mathbf{y}=\mathbf{y}(\mathbf{x};w)</span> to the data manifold <span class="math inline">\mathcal{D}</span></li>
<li>We assume that the distribution of latent data is given by a set of discrete points <span class="math inline">\mathbf{x}_k</span> spaced on a regular grid. This was inspired by the Self organizing map and provides the nice topological properties of the GTM.</li>
<li>Given the Bayesian prior for <span class="math inline">p(\mathbf{x})</span>, we then can construct the <em>log-likelihood</em> function <span class="math inline">\ell(w,\beta)</span> which tells us the likelihood of obtaining our data <span class="math inline">\mathbf{t}_n</span> given our model for the latent variable transformation (parametrized by weights <span class="math inline">w</span>) and assumed Gaussian distribution of data points (with covariance <span class="math inline">\beta^{-1}</span>).</li>
<li>Maximizing <span class="math inline">\ell(w, \beta)</span> with respect to <span class="math inline">w</span> and <span class="math inline">\beta</span> will yield our fitted latent-variable model.</li>
<li>We can then use Baye‚Äôs rule to invert the distribution and obtain <span class="math inline">p(\mathbf{x_k}\vert \mathbf{t}_n)</span>, i.e.&nbsp;the responsability of the <span class="math inline">k^{th}</span> latent variable for producing the <span class="math inline">n^{th}</span> data point.</li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>We should make the notion of vector, manifold, and point here more precise.</p>
</div>
</div>
</section>
</section>
<section id="em-algorithm-for-gtm" class="level1">
<h1>EM Algorithm for GTM</h1>
<p>Theoretically at this point we have all we need to solve the problem. We can assume some initial guess for <span class="math inline">w</span> and <span class="math inline">\beta</span> and proceed with any of our favorite optimization routines. However the double sum in <span class="math inline">\ell</span> presents some computational complexity that suggests we might seek an alternative optimization scheme. We still have not yet defined the specific form for the nonlinear latent variable transformation <span class="math inline">\mathbf{y}(\mathbf{x}; w)</span> and consequently can utilize the oportunity to manufacture a form for <span class="math inline">\mathbf{y}</span> amenable to an expectation-maximization scheme.</p>
<section id="the-expectation-step" class="level2">
<h2 class="anchored" data-anchor-id="the-expectation-step">The Expectation Step</h2>
<p>To begin, suppose we already have some values for the parameters <span class="math inline">w_{o}</span> and <span class="math inline">\beta_{o}</span> (<span class="math inline">o</span> for <em>old</em>). To make our lives simpler, we‚Äôll write <span class="math inline">\theta :=(w,\beta)</span> to save space. Given these values, we can compute the responsabilities <span class="math inline">r_{kn}</span> <span class="math display">\begin{align}
    r_{kn} := p(\mathbf{x}_k \vert \mathbf{t}_n, \theta_o) &amp;= \frac{p(\mathbf{t}_n\vert \mathbf{x}_k, \theta_o)p(\mathbf{x}_k\vert \theta_0 )}{p(\mathbf{t}_n\vert \theta_0 )} \\
    &amp;= \frac{p(\mathbf{t}_n \vert \mathbf{x}_k, \theta_o)p(\mathbf{x}_k \vert \theta_o)}{p(\mathbf{t}_n \vert \theta_o)} \\
    &amp;= \frac{p(\mathbf{t}_n \vert \mathbf{x}_k, \theta_o)p(\mathbf{x}_k \vert \theta_o)}{\sum_{k'}^K p(\mathbf{t}_n\vert \mathbf{x}_{k'},\theta_o)p(\mathbf{x}_{k'},\theta_o)} \\
    &amp;= \frac{p(\mathbf{t}_n \vert \mathbf{x}_k, \theta_o)\frac{p(\mathbf{x}_k,\theta_o)}{p(\theta_o)}}{\sum_{k'}^K p(\mathbf{t}_n\vert \mathbf{x}_{k'},\theta_o)p(\mathbf{x}_{k'}\vert\theta_o)} \\
    &amp;= \frac{p(\mathbf{t}_n \vert \mathbf{x}_k, \theta_o)\frac{p(\mathbf{x}_k,\theta_o)}{p(\theta_o)}}{\sum_{k'}^K p(\mathbf{t}_n\vert \mathbf{x}_{k'},\theta_o)\frac{p(\mathbf{x}_{k'},\theta_o)}{p(\theta_o)}} \\
    &amp;= \frac{p(\mathbf{t}_n \vert \mathbf{x}_k, \theta_o)\frac{p(\mathbf{x}_k,\theta_o)}{p(\theta_o)}}{\sum_{k'}^K p(\mathbf{t}_n\vert \mathbf{x}_{k'},\theta_o)\frac{p(\mathbf{x}_{k'},\theta_o)}{p(\theta_o)}} \\
    &amp;= \frac{p(\mathbf{t}_n \vert \mathbf{x}_k, \theta_o)p(\mathbf{x}_k,\theta_o)}{\sum_{k'}^K p(\mathbf{t}_n\vert \mathbf{x}_{k'},\theta_o)p(\mathbf{x}_{k'},\theta_o)} \\
    &amp;= \frac{p(\mathbf{t}_n \vert \mathbf{x}_k, \theta_o)p(\mathbf{x}_k)p(\theta_o)}{\sum_{k'}^K p(\mathbf{t}_n\vert \mathbf{x}_{k'},\theta_o)p(\mathbf{x}_{k'})p(\theta_o)} \\
    &amp;= \frac{p(\mathbf{t}_n \vert \mathbf{x}_k, \theta_o)p(\mathbf{x}_k)}{\sum_{k'}^K p(\mathbf{t}_n\vert \mathbf{x}_{k'},\theta_o)p(\mathbf{x}_{k'})} \\
    &amp;= \frac{p(\mathbf{t}_n \vert \mathbf{x}_k, \theta_o)\frac{1}{K}}{\sum_{k'}^K p(\mathbf{t}_n\vert \mathbf{x}_{k'},\theta_o)\frac{1}{K}} \\
    &amp;= \frac{p(\mathbf{t}_n \vert \mathbf{x}_k, \theta_o)}{\sum_{k'}^K p(\mathbf{t}_n\vert \mathbf{x}_{k'},\theta_o)} \\
\end{align}</span> <span class="math display">\begin{equation}
    \boxed{r_{kn} = \frac{p(\mathbf{t}_n\vert \mathbf{x}_k, \theta_o)}{\sum_{k'}^K p(\mathbf{t}_n \vert \mathbf{x}_{k'}, \theta_o)}},
\end{equation}</span></p>
<p>or in words, <span class="math inline">r_{kn}</span> is the posterior i.e.&nbsp;the probability that the <span class="math inline">n^{th}</span> data point <em>came from</em> the <span class="math inline">k^{th}</span> latent node <span class="math inline">\mathbf{x}_k</span>. This is the expectation step</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The latent variable points <span class="math inline">\mathbf{x}_k</span> don‚Äôt move but their transformed locations in the embedded data manifold <em>do</em> as the weights <span class="math inline">w</span> are updated.</p>
</div>
</div>
</section>
<section id="deciding-on-a-form-for-mathbfy" class="level2">
<h2 class="anchored" data-anchor-id="deciding-on-a-form-for-mathbfy">Deciding on a form for <span class="math inline">\mathbf{y}</span></h2>
<p><span class="math inline">\mathbf{y}</span> can be any nonlinear, parametric model (for example a multi-layer-perceptron). FOr convenience, we choose a generalized (kernalized) linear regression: <span class="math display">\begin{equation}
    \mathbf{y} := W\phi(\mathbf{x})
\end{equation}</span> where <span class="math inline">W\in\mathbb{R}^{D\times M}</span> and <span class="math inline">\phi(\mathbf{x})\in\mathbb{R}^M</span>. Here <span class="math inline">\phi_m</span> is the <span class="math inline">m^{th}</span> basis function applied to <span class="math inline">\mathbf{x}</span>. In order to capture linear <em>and</em> nonlinear effects, a combination of linear basis functions and Radial Basis Functions (RBF) are used so that <span class="math display">\begin{equation}
    \phi_m(\mathbf{x}) = \begin{cases}
        \exp(- \frac{1}{2\sigma}\lvert \mathbf{x}-\mathbf{\mu}_m\rvert^2) &amp; m \leq M_{NL} \\
        \mathbf{x}^{(l)} &amp; m = M_{NL} + l, \qquad l\in 1, ..., L \\
        1 &amp; m = M_{NL} + L + 1 = M
    \end{cases}
\end{equation}</span> i.e.&nbsp;a combination of <span class="math inline">M_{NL}</span> gausians with centers <span class="math inline">\mathbf{\mu}_m</span> and <span class="math inline">L</span> linear functions. For convenience, we can write this in matrix form: <span class="math display">\begin{equation}
    Y = \Phi W
\end{equation}</span> with <span class="math inline">\Phi \in \mathbb{R}^{K\times M}</span> so that <span class="math inline">\Phi_{km} = \phi_m(\mathbf{x}_k)</span>.</p>
</section>
<section id="the-maximization-step" class="level2">
<h2 class="anchored" data-anchor-id="the-maximization-step">The Maximization Step</h2>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>We should add an derivation that demonstrates why EM is <em>guarenteed</em> to increase the log-likelihood function.</p>
</div>
</div>
<p>We now derive the maximization step, or in other words, given the previous values <span class="math inline">\theta_o</span> and the responsabilities <span class="math inline">r_{kn}</span>, how do we obtain <span class="math inline">\theta_n</span> (n for new) so that our log-likelihood function increases? We differentiate <span class="math inline">\ell</span> with respect to the parameters while treating <span class="math inline">r_{kn}</span> as constant: <span class="math display">\begin{align}
    \ell(w,\beta) &amp;= \sum_n^N \ln \left(\frac{1}{K}\sum_k^K p(\mathbf{t}_n\vert \mathbf{x}_k, w, \beta ) \right) \\
    0 &amp;= \frac{\partial}{\partial w_{md}}\ell(w, \beta) \\
    &amp;= \frac{\partial}{\partial w_{md}} \sum_n^N \ln \left(\frac{1}{K}\sum_k^K p(\mathbf{t}_n\vert \mathbf{x}_k, w, \beta ) \right) \\
    &amp;= \sum_n^N \frac{1}{\frac{1}{K}\sum_{k'}^Kp(\mathbf{t}_n\vert \mathbf{x}_{k'}, w, \beta)}\frac{1}{K}\frac{\partial}{\partial w_{md}}\sum_k^K p(\mathbf{t}_n \vert \mathbf{x}_k, w, \beta) \\
    &amp;= \sum_n^N\sum_k^K \frac{ \frac{\partial}{\partial w_{md}} p(\mathbf{t}_n\vert\mathbf{x}_k,w,\beta)  }{\sum_{k'}^K p(\mathbf{t}_n\vert \mathbf{x}_{k'},w,\beta)} \\
    &amp;= \sum_n^N\sum_k^K \frac{p(\mathbf{t}_n\vert \mathbf{x}_k, w, \beta)}{\sum_{k'}^K p(\mathbf{t}_n\vert \mathbf{x}_{k'},w,\beta)} \frac{\partial}{\partial w_{md}} \left\{ \frac{-\beta}{2}\sum_d^D \left(t_n^{(d)} - y_k^{(d)} \right)^2 \right\}  \\
    &amp;= \sum_n^N\sum_k^K r_{nk} \frac{\partial}{\partial w_{md}} \left\{ \frac{-\beta}{2}\sum_d^D \left(t_n^{(d)} - y_k^{(d)} \right)^2 \right\}  \\
    &amp;= \sum_n^N\sum_k^K r_{nk}(-\beta)  \sum_d^D \left(t_n^{(d)} - y_k^{(d)} \right) \frac{\partial y_k^{(d)}}{\partial w_{md}} \\
    &amp;= \sum_n^N\sum_k^K r_{nk}\beta   \sum_d^D \left( y_k^{(d)} - t_n^{(d)} \right) \frac{\partial}{\partial w_{md}}\sum_{s}^M\phi_s(\mathbf{x}_k)w_{sd} \\
    &amp;= \sum_n^N\sum_k^K r_{nk}\beta   \sum_d^D \left( y_k^{(d)} - t_n^{(d)} \right) \sum_{s}^M\phi_s(\mathbf{x}_k)\delta_{ms} \\
    &amp;= \sum_n^N\sum_k^K r_{nk}\beta   \sum_d^D \left( y_k^{(d)} - t_n^{(d)} \right) \phi_m(\mathbf{x}_k) \\
    &amp;= \sum_n^N \sum_k^K \sum_d^D \beta \; r_{nk}  \left( y_k^{(d)} - t_n^{(d)} \right) \phi_m(\mathbf{x}_k) \\
\end{align}</span></p>
<p>Let us now define the diagonal matrix <span class="math inline">G</span> given by <span class="math inline">G_{kk} = \sum_n r_{nk}</span>. Then the system of equations has become: <span class="math display">\begin{align}
    \sum_n \sum_k \sum_d r_{nk} y_k^{(d)}\phi_m(\mathbf{x}_k) &amp;= \sum_n \sum_k \sum_d r_{nk}t_n^{(d)}\phi_m(\mathbf{x}_k) \\
    \sum_n\sum_k\sum_d r_{nk} \left( \sum_s \phi_s(\mathbf{x}_k)w_{sd} \right) \phi_m(\mathbf{x}_k) &amp;= \sum_n \sum_k \sum_d r_{nk}t_n^{(d)}\phi_m(\mathbf{x}_k) \\
    \sum_k\sum_d\sum_s G_{kk}\Phi_{sk}w_{sd}\Phi_{mk} &amp;= \sum_n\sum_k\sum_d r_{nk}t_{nd}\Phi_{mk}
\end{align}</span> where <span class="math inline">\Phi</span> is the matrix with components <span class="math inline">\Phi_{mk} = \phi_m(\mathbf{x}_k)</span>. Similarly define <span class="math inline">R</span> as the matrix with components <span class="math inline">R_{nk}=r_{nk}</span> and <span class="math inline">T</span> as the data matrix with components <span class="math inline">T_{nd}=t_n^{(d)}</span>. With these convenctions, the entire system can be written as <span class="math display">\begin{equation}
    \Phi^T G \Phi W = \Phi^T R T
\end{equation}</span></p>
<p>Performing the same procedure for the derivative w.r.t. <span class="math inline">\beta</span>, we find <span class="math display">\begin{equation}
    \frac{1}{\beta} = \frac{1}{ND}\sum_n^N\sum_k^K r_{kn} \lVert \mathbf{y}(\mathbf{x}_k, w) - \mathbf{t}_n\rVert^2
\end{equation}</span></p>
<p>Thus, once we have determined the responsabilities via the <em>expectation step</em>, we perform the maximization step via <span class="math display">\begin{equation}
    \boxed{ \Phi^T G_{\text{old}}\Phi W_{\text{new}} = \Phi^TR_{\text{old}}T}
\end{equation}</span> <span class="math display">\begin{equation}
    \boxed{\frac{1}{\beta_{\text{new}}} = \frac{1}{ND}\sum_n^N\sum_k^K r_{kn}^{\text{(old)}}\lVert \phi(\mathbf{y}(\mathbf{x}_k, W_{\text{new}}) - \mathbf{t}_n \rVert^2}
\end{equation}</span></p>
</section>
<section id="initialization-for-the-em-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="initialization-for-the-em-algorithm">Initialization for the EM Algorithm</h2>
<p>The last needed piece to be able to fit our GTM model is a plan for how to initialize the model parameters in <span class="math inline">W_{md}</span> and <span class="math inline">\beta</span>. A simple strategy is to randomnly initialize the weights before training. Once can do a slightly better job by forcing the weight variance to yield a variance in the projected values <span class="math inline">\mathbf{y}</span> that matches the variance of the data. This is easily accomplished by means of principal component analysis. We use the following strategy:</p>
<ol type="1">
<li>Obtain the data covariance matrix <code>U</code> whose columns are the principal components of our dataset <span class="math inline">\mathcal{D}</span>.</li>
<li>Keep only the first two principal components as our latent space will be 2-dimensional.</li>
<li>Fit <span class="math inline">W</span> so that <span class="math inline">W\Phi \approx UX^T</span>.</li>
<li>Set <span class="math inline">\beta^{-1}</span> to be the variance of the third principal component vector.</li>
</ol>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>We should check the dimensions of the equation in <code>3.</code> so that everything matches.</p>
</div>
</div>
</section>
<section id="em-algorithm-summary" class="level2">
<h2 class="anchored" data-anchor-id="em-algorithm-summary">EM Algorithm Summary</h2>
<ol type="1">
<li>Generate a grid of latent points <span class="math inline">\{ \mathbf{x}_k \}</span> with <span class="math inline">k=1,...,K</span>.</li>
<li>Generate a grid of basis function centers <span class="math inline">\{\mathbf{\mu}_m\}</span> with <span class="math inline">m=1, ..., M</span>.</li>
<li>Select the basis function width <span class="math inline">\sigma</span>.</li>
<li>Compute the matrix of basis function activations <span class="math inline">\Phi</span> where <span class="math inline">\Phi_{mk} = \Phi_m(\mathbf{x}_k)</span>.</li>
<li>Initialize the weight matrix <span class="math inline">W</span> randomly or with PCA</li>
<li>Initialize <span class="math inline">\beta</span>.</li>
<li>If desired, select a value <span class="math inline">\alpha</span> to allow for weight regularization, i.e.&nbsp;<span class="math inline">(\Phi^TG\Phi + \frac{\alpha}{\beta}I)W = \Phi^TRT</span>. This corresponds to specifying a Bayesian prior distribution over <span class="math inline">W</span> with <span class="math display">\begin{equation}
p(W) = \left(\frac{\alpha}{2\pi}\right)^{W/2}\exp(-\frac{\alpha}{2}\lVert W \rVert^2)
\end{equation}</span></li>
<li>Compute difference matrix <span class="math inline">\mathbf{\Delta}</span> with <span class="math inline">\Delta_{kn} := \lVert \mathbf{t}_n - \phi_k W \rVert^2</span></li>
<li>Repeat the following until <em>convergence</em>
<ol type="1">
<li>Compute the responsability matrix <span class="math inline">R</span> using <span class="math inline">\Delta</span> and <span class="math inline">\beta</span></li>
<li>Compute <span class="math inline">G</span> from the responsability matrix <span class="math inline">R</span></li>
<li>Update the weight matrix <span class="math inline">W</span> with <span class="math inline">W = (\Phi^TG\Phi)^{-1}\Phi^TRT</span></li>
<li>Compute updated <span class="math inline">\mathbf{\Delta}</span></li>
<li>Update <span class="math inline">\beta</span></li>
</ol></li>
</ol>
</section>
</section>
<section id="visualization-of-results" class="level1">
<h1>Visualization of Results</h1>
<p>Once we have fit a GTM model to our dataset <span class="math inline">\mathcal{D}</span> and determined suitable parameters <span class="math inline">W</span> and <span class="math inline">\beta</span>, we can define a distribution in the data space conditioned on our latent variables <span class="math inline">\mathbf{x}_k</span>, that is <span class="math inline">p(\mathbf{t}\vert \mathbf{x}_k</span> for <span class="math inline">k=1,...,K</span>. Using Baye‚Äôs theorem, we can then compute the posterior distribution in the <em>latent space</em> for any point in the data space, in other words, given a datapoint <span class="math inline">\mathbf{t}</span>, how much is it <em>explained</em> by the <span class="math inline">k^{th}</span> latent variable <span class="math inline">p(\mathbf{x}_k \vert \mathbf{t}</span>. For each datapoint, this would result in a matrix of responsabilities <span class="math inline">R</span>. This is probably to cumbersome to visualize for each point, so instead one may resort to visualizing the mean and mode of the distribution: <span class="math display">\begin{align}
    \langle \mathbf{x} \vert \mathbf{t}_n, W, \beta \rangle &amp;= \int p(\mathbf{x}\vert \mathbf{t}_n, W, \beta) \mathbf{x}d\mathbf{x} \\
    &amp;= \int \frac{p(\mathbf{t}_n\vert \mathbf{x}, W, \beta)p(\mathbf{x})}{\sum_{k'}p(\mathbf{t}_n\vert \mathbf{x}_{k'}, W, \beta)p(\mathbf{x}_{k'})}\mathbf{x}d\mathbf{x}\\
    &amp;= \int \frac{p(\mathbf{t}_n\vert \mathbf{x}, W, \beta)p(\mathbf{x})}{\sum_{k'}p(\mathbf{t}_n\vert \mathbf{x}_{k'}, W, \beta)p(\mathbf{x}_{k'})}\mathbf{x}d\mathbf{x}\\
    &amp;= \int \frac{p(\mathbf{t}_n\vert \mathbf{x}, W, \beta)\frac{1}{K}\sum_k\delta(\mathbf{x}-\mathbf{x}_k)}{\sum_{k'}p(\mathbf{t}_n\vert \mathbf{x}_{k'}, W, \beta)p(\mathbf{x}_{k'})}\mathbf{x}d\mathbf{x}\\
    &amp;= \sum_k R_{kn} \mathbf{x}_k
\end{align}</span> <span class="math display">\begin{equation}
    \boxed{\langle \mathbf{x} \vert \mathbf{t}_n, W, \beta \rangle = \sum_k^K R_{kn}\mathbf{x}_k }
\end{equation}</span></p>
<p>If the distribution is multimodal, it is also advantageous to compute the mode: <span class="math display">\begin{align}
    \boxed{\mathbf{x}_{\text{mode}} = \mathbf{x}_{k^{\text{max}}} \;\;\text{where}\;\; k^{\text{max}} = \underset{\{k\}}{\text{argmax}} R_{kn}}
\end{align}</span></p>
</section>
<section id="coding-things-up" class="level1">
<h1>Coding Things Up!</h1>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">Pkg </span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="bu">Pkg</span>.<span class="fu">activate</span>(<span class="st">"."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>  Activating project at `~/gitrepos/machine-learning/GTM.jl/notes`</code></pre>
</div>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">Plots</span>, <span class="bu">LinearAlgebra</span>, <span class="bu">Statistics</span>, <span class="bu">Distributions</span>, <span class="bu">MLJ</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Create a sample dataset using MLJ. We will use a classification set so that we can see if GTM can distinguish the classes after fitting.</p>
<p>The table <code>X</code> contains our data (each row is one datum) with class labels in <code>y</code></p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">Tables</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>DataX,Datay<span class="op">=</span> <span class="fu">make_blobs</span>(<span class="fl">500</span>, <span class="fl">10</span>; centers<span class="op">=</span><span class="fl">5</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>ùíü <span class="op">=</span> Tables.<span class="fu">matrix</span>(DataX)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>500√ó10 Matrix{Float64}:
 -6.89213  -0.591606    8.79375  ‚Ä¶   2.6749    -4.47481    2.8642
 -5.76369   0.72814     6.09521     -5.41723   -1.16301    7.30158
  8.94004  -0.591369    9.1815      -4.36022    0.547718  -5.47387
  5.27456   5.29026    -8.53169     -2.69048    8.02274    0.23124
 -6.38      7.86484    -8.12333      1.88265    3.91803    0.228869
 -4.80034   2.92024     6.43425  ‚Ä¶  -7.60034    0.842018   5.43513
  3.34243   3.09758    -8.48063     -2.65571    8.08795    0.560071
  5.42568   5.77196    -9.44534     -3.19474    9.72166   -0.220025
 -4.20296   7.32864    -8.09361     -0.913384   3.59333    1.8732
 -6.85845   9.43648    -8.29228      0.720007   3.75365    0.119073
 -4.75319   1.49454     5.74735  ‚Ä¶  -5.81812   -0.223656   6.68464
  5.4441    6.48556    -7.7276      -1.12786    9.56342   -1.3166
  4.73433   4.78356    -8.41132     -3.33798    7.3056     0.68346
  ‚ãÆ                              ‚ã±                        
 -4.07738   2.36815     5.90354     -5.71817   -0.459386   6.85579
  8.42064  -1.66222     7.11764     -5.09643    1.89773   -5.06988
  6.21052   4.53885    -8.40088  ‚Ä¶  -3.17634    8.79434   -0.0294988
 -5.23742   9.98947    -6.99824      1.76778    1.53851   -0.0457416
 -6.65271   9.06775    -6.70772     -0.43361    3.18299   -0.00959754
 -5.7589   -2.32311    10.3103       3.74598   -6.75062    3.85739
  3.88383   5.09058   -10.1019      -3.3818     9.38426    0.119645
 -5.76267  -3.84153     7.79376  ‚Ä¶   4.14541   -6.24317    3.79281
  9.03166  -1.22142     7.54346     -4.78046    1.97903   -4.75352
  4.16339   3.60893    -9.71716     -4.56898    9.0408    -0.182844
  3.74834   3.54722   -10.0067      -3.98367    8.80101    0.711452
 -5.81974   0.846791    5.70333     -6.02427   -0.92559    5.08015</code></pre>
</div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. GTM  parameters</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="fl">10</span>  <span class="co"># there are K=k¬≤ total latent nodes</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="fl">5</span>   <span class="co"># there are M=m¬≤ basis functions (centers of our RBFs) </span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>œÉ <span class="op">=</span> <span class="fl">1.0</span> <span class="co"># the œÉ¬≤ is the variance in our RBFs</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>n_nodes <span class="op">=</span> k<span class="op">*</span>k </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>n_rbf_centers <span class="op">=</span> m<span class="op">*</span>m </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>25</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Create node matrix X</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="fu">range</span>(<span class="op">-</span><span class="fl">1.0</span>, <span class="fl">1.0</span>, length<span class="op">=</span>k) </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> <span class="fu">vcat</span>([x[i] for i <span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(x), j <span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(x)]<span class="op">...</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>ys <span class="op">=</span> <span class="fu">vcat</span>([x[j] for i <span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(x), j<span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(x)]<span class="op">...</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> <span class="fu">hcat</span>(xs, ys)  <span class="co"># X[:,1] are the x positions, X[:,2] are the y positions</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="fu">size</span>(X,<span class="fl">1</span>) <span class="op">==</span> n_nodes</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="fu">scatter</span>(X[<span class="op">:</span>,<span class="fl">1</span>], X[<span class="op">:</span>,<span class="fl">2</span>], color<span class="op">=:</span>black, label<span class="op">=</span><span class="st">"node locations"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<p><img src="generative_topographic_mapping_files/figure-html/cell-6-output-1.svg" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Create rbf centers matrix M</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="fu">range</span>(<span class="op">-</span><span class="fl">1.0</span>, <span class="fl">1.0</span>, length<span class="op">=</span>m) </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> <span class="fu">vcat</span>([x[i] for i <span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(x), j <span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(x)]<span class="op">...</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>ys <span class="op">=</span> <span class="fu">vcat</span>([x[j] for i <span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(x), j<span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(x)]<span class="op">...</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>M <span class="op">=</span> <span class="fu">hcat</span>(xs, ys)  <span class="co"># X[:,1] are the x positions, X[:,2] are the y positions</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="fu">size</span>(M,<span class="fl">1</span>) <span class="op">==</span> n_rbf_centers</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="fu">scatter!</span>(M[<span class="op">:</span>,<span class="fl">1</span>], M[<span class="op">:</span>,<span class="fl">2</span>], color<span class="op">=:</span>purple, label<span class="op">=</span><span class="st">"rbf centers"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<p><img src="generative_topographic_mapping_files/figure-html/cell-7-output-1.svg" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Initialize rbf width</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize the rbf variance to the mean squared distance between rbf centers</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">Distances</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>œÉ <span class="op">=</span> <span class="fu">mean</span>(<span class="fu">sqeuclidean</span>(M[<span class="op">:</span>,<span class="fl">1</span>], M[<span class="op">:</span>,<span class="fl">2</span>]))  <span class="co"># sqeuclidean is Squared Euclidean distance</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>25.0</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Create rbf matrix Œ¶</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># this matrix contains the RBF basis functions applied to each latent point *plus* one constant row to enable fitting a bias. </span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>Œ¶ <span class="op">=</span> <span class="fu">zeros</span>(n_nodes, n_rbf_centers <span class="op">+</span> <span class="fl">1</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> j <span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span>n_rbf_centers, i<span class="op">‚àà</span><span class="fl">1</span><span class="op">:</span>n_nodes</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    Œ¶[i,j] <span class="op">=</span> <span class="fu">exp</span>(<span class="fu">-sqeuclidean</span>(X[i,<span class="op">:</span>], M[j,<span class="op">:</span>])<span class="op">/</span>(<span class="fl">2</span>œÉ))</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># set the last column to ones </span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>Œ¶[<span class="op">:</span>,<span class="kw">end</span>] <span class="op">.=</span> <span class="fl">1</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>Œ¶</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>100√ó26 Matrix{Float64}:
 1.0       0.995012  0.980199  0.955997  ‚Ä¶  0.904837  0.882497  0.852144  1.0
 0.999013  0.998458  0.987974  0.967873     0.912015  0.893459  0.866572  1.0
 0.996057  0.999938  0.993846  0.977963     0.917436  0.902773  0.879506  1.0
 0.991151  0.999445  0.99778   0.986207     0.921067  0.910384  0.890871  1.0
 0.984322  0.99698   0.999753  0.992559     0.922888  0.916247  0.900602  1.0
 0.975611  0.992559  0.999753  0.99698   ‚Ä¶  0.922888  0.920328  0.908643  1.0
 0.965069  0.986207  0.99778   0.999445     0.921067  0.922604  0.914947  1.0
 0.952757  0.977963  0.993846  0.999938     0.917436  0.923059  0.919477  1.0
 0.938746  0.967873  0.987974  0.998458     0.912015  0.921693  0.922205  1.0
 0.923116  0.955997  0.980199  0.995012     0.904837  0.918512  0.923116  1.0
 0.999013  0.99403   0.979231  0.955054  ‚Ä¶  0.920158  0.897439  0.866572  1.0
 0.998027  0.997472  0.986999  0.966918     0.927457  0.908587  0.881245  1.0
 0.995074  0.998951  0.992865  0.976997     0.93297   0.918059  0.894398  1.0
 ‚ãÆ                                       ‚ã±                                ‚ãÆ
 0.881245  0.908587  0.927457  0.937299     0.986999  0.997472  0.998027  1.0
 0.866572  0.897439  0.920158  0.934064     0.979231  0.99403   0.999013  1.0
 0.923116  0.918512  0.904837  0.882497  ‚Ä¶  0.980199  0.955997  0.923116  1.0
 0.922205  0.921693  0.912015  0.893459     0.987974  0.967873  0.938746  1.0
 0.919477  0.923059  0.917436  0.902773     0.993846  0.977963  0.952757  1.0
 0.914947  0.922604  0.921067  0.910384     0.99778   0.986207  0.965069  1.0
 0.908643  0.920328  0.922888  0.916247     0.999753  0.992559  0.975611  1.0
 0.900602  0.916247  0.922888  0.920328  ‚Ä¶  0.999753  0.99698   0.984322  1.0
 0.890871  0.910384  0.921067  0.922604     0.99778   0.999445  0.991151  1.0
 0.879506  0.902773  0.917436  0.923059     0.993846  0.999938  0.996057  1.0
 0.866572  0.893459  0.912015  0.921693     0.987974  0.998458  0.999013  1.0
 0.852144  0.882497  0.904837  0.918512     0.980199  0.995012  1.0       1.0</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. perform PCA on data to set up linear basis functions. </span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">MultivariateStats</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># dataset has rows as our records. PCA wants them as the columns</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="fu">size</span>(ùíü)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> <span class="fu">fit</span>(PCA, ùíü<span class="ch">'; maxoutdim=3)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>PCA(indim = 10, outdim = 3, principalratio = 0.870371001924444)

Pattern matrix (unstandardized loadings):
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
          PC1        PC2        PC3
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
1   -2.23544   -4.60112    3.2542
2   -3.05877    2.30219   -0.892043
3    7.49359   -2.10196    1.88858
4    1.4984     4.03441    2.76862
5    0.72444   -0.584785  -4.10281
6    0.645328   6.18586    1.02383
7   -2.00928    1.46296    1.18199
8    0.361678  -0.608499  -3.2941
9   -4.24339   -0.402499   1.49673
10   1.80407    2.40886   -0.845688
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

Importance of components:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                                 PC1        PC2        PC3
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
SS Loadings (Eigenvalues)  99.1226    94.247     55.7024
Variance explained          0.34638    0.329342   0.19465
Cumulative variance         0.34638    0.675721   0.870371
Proportion explained        0.397968   0.378392   0.22364
Cumulative proportion       0.397968   0.77636    1.0
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</code></pre>
</div>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. Set U matrix to first two principle axes (since latent space is two dimensional)</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>pca_vecs <span class="op">=</span> <span class="fu">projection</span>(pca)  <span class="co"># this results the princiap component vectors (columns) sorted in order of explained variance </span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>pca_var <span class="op">=</span> <span class="fu">principalvars</span>(pca)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="fu">size</span>(pca_vecs)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="fu">size</span>(pca_var)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> pca_vecs[<span class="op">:</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">2</span>] </span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="op">‚àà</span> <span class="fu">axes</span>(U,<span class="fl">2</span>)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    U[<span class="op">:</span>,i] <span class="op">.=</span> <span class="fu">sqrt</span>(pca_var[i])<span class="op">.*</span>U[<span class="op">:</span>,i]  <span class="co"># we still need to figure out why they're scaling by the explained variance...</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>U</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>10√ó2 Matrix{Float64}:
 -2.23544   -4.60112
 -3.05877    2.30219
  7.49359   -2.10196
  1.4984     4.03441
  0.72444   -0.584785
  0.645328   6.18586
 -2.00928    1.46296
  0.361678  -0.608499
 -4.24339   -0.402499
  1.80407    2.40886</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 8. Initialize parameter matrix W using Œ¶, and U</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">Init_W_Matrix</span>(X,Œ¶,U)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We want to find W such that WŒ¶' = UX'</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># therefore, W' is the solution to Œ¶'‚ãÖŒ¶‚ãÖW' = Œ¶'UX'</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ((Œ¶<span class="ch">'*Œ¶)\(Œ¶'</span><span class="op">*</span>X<span class="op">*</span>U<span class="op">'</span>))<span class="ch">'</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>Init_W_Matrix (generic function with 1 method)</code></pre>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>I have done this differently thant than <code>ugtm.py</code>. They standardize the vectors first. I think they also have a typo in how they solve for W (they leave <code>UX'</code> out until the end. See <a href="https://github.com/hagax8/ugtm/blob/master/ugtm/ugtm_core.py#L145">this link</a>. Maybe this is just an approximation to speed things up.</p>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> <span class="fu">Init_W_Matrix</span>(X,Œ¶,U)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>10√ó26 adjoint(::Matrix{Float64}) with eltype Float64:
 -18703.4         1.14544e5  -29127.3    ‚Ä¶   41018.6    -76014.3    53.9257
  -4857.21    19306.1         -4947.7        11294.4    -14737.6     8.42081
  20432.1        -1.03849e5   26486.0       -46118.4     72842.0   -47.5287
  14828.5    -91966.7         23382.0       -32449.5     60818.9   -43.3706
   1055.05    -3940.59         1011.32       -2468.83     3079.99   -1.69384
  17114.0        -1.10708e5   28130.3    ‚Ä¶  -37170.1     72381.1   -52.4975
  -3309.64    13470.6         -3450.43        7676.45   -10193.3     5.90667
   -236.655    3092.17         -780.273        417.986   -1749.06    1.56091
 -15411.2     84264.3        -21464.8        34420.5    -57786.0    39.023
  11948.5    -71591.5         18210.9       -26301.9     47802.2   -33.603</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>W2 <span class="op">=</span> U<span class="op">*</span>X<span class="op">'</span><span class="fu">*</span>((Œ¶<span class="ch">'*Œ¶)\ Œ¶'</span>)<span class="ch">'  # this is how they do it... </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>10√ó26 Matrix{Float64}:
 -18701.3         1.14527e5  -29122.1    ‚Ä¶   41012.4    -76002.2    53.9162
  -4858.91    19318.5         -4952.73       11298.6    -14745.9     8.42715
  20434.3        -1.03864e5   26493.2       -46123.5     72851.8   -47.5361
  14826.6    -91951.7         23377.3       -32444.1     60808.2   -43.3623
   1055.47    -3943.7          1012.56       -2469.9      3082.06   -1.69543
  17110.7        -1.10683e5   28121.9    ‚Ä¶  -37161.0     72363.3   -52.4838
  -3310.72    13478.5         -3453.63        7679.15   -10198.5     5.91067
   -236.264    3089.25         -779.192        416.963   -1747.07    1.55938
 -15411.6     84266.7        -21466.7        34421.1    -57787.1    39.0238
  11947.6    -71583.4         18208.5       -26298.8     47796.3   -33.5984</code></pre>
</div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 9. Initialize Y using W and Œ¶</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> W<span class="op">*</span>Œ¶<span class="ch">'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>10√ó100 Matrix{Float64}:
  6.82787    6.34193     5.85095   ‚Ä¶  -5.83571   -6.33801    -6.84432
  0.754489   0.0772084  -0.601325      0.604246  -0.0766779  -0.758579
 -5.38248   -3.72831    -2.06876       2.05423    3.72502     5.40008
 -5.5259    -5.20154    -4.87318       4.86099    5.19838     5.53897
 -0.139206   0.0212586   0.181994     -0.182603  -0.021362    0.14009
 -6.82314   -6.68984    -6.5519    ‚Ä¶   6.53737    6.68598     6.8383
  0.544894   0.100064   -0.345621      0.347642  -0.0996882  -0.547687
  0.246684   0.327252    0.407746     -0.40739   -0.327125   -0.246921
  4.63889    3.70448     2.76597      -2.75442   -3.70172    -4.65227
 -4.2074    -3.81336    -3.4161        3.40653    3.81093     4.21789</code></pre>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 10. Set noise varaiance parameter</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>Œ≤‚Åª¬π <span class="op">=</span> <span class="fu">maximum</span>([<span class="fu">mean</span>(<span class="fu">pairwise</span>(sqeuclidean, Y, dims<span class="op">=</span><span class="fl">2</span>))<span class="op">/</span><span class="fl">2</span>, pca_var[<span class="kw">end</span>]])</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co">#  Œ≤‚Åª¬π = pca_var[end]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>78.78030347169494</code></pre>
</div>
</div>
<p>We now have everything we need to begin the EM algorithm. The Procedure is as follows:</p>
<ol type="1">
<li>Create distance matrix between projections <code>Y</code> and the data <code>T</code>.</li>
<li>Continue until convergence:
<ol type="1">
<li>Update data distribution <code>P</code></li>
<li>Update responsabilities <code>R</code></li>
<li>Update diagonal matrix <code>G</code></li>
<li>Update parameter matrix <code>W</code></li>
<li>Update manifold matrix <code>Y</code></li>
<li>Update distance matrix <code>D</code></li>
<li>Update variance <code>Œ≤‚Åª¬π</code></li>
<li>Estimate log-likelihood</li>
<li>Check for convergence.</li>
</ol></li>
<li>Compute represenation 1: <code>means</code></li>
<li>Compute representation 2: <code>modes</code></li>
</ol>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="fu">size</span>(ùíü))</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="fu">size</span>(Y))</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> <span class="fu">pairwise</span>(sqeuclidean, Y, ùíü<span class="ch">')'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(500, 10)
(10, 100)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>500√ó100 adjoint(::Matrix{Float64}) with eltype Float64:
 603.094   517.11   440.435  373.217  ‚Ä¶  538.835  510.758  492.637   484.559
 913.456   838.553  772.75   716.206     146.954  129.437  121.697   123.832
 328.496   273.408  227.8    191.804     584.487  587.708  601.027   624.525
 109.075   133.796  168.263  212.576     662.189  745.829  839.779   944.119
 501.067   498.385  505.135  521.439     276.184  331.661  397.186   472.849
 843.339   776.729  719.268  671.107  ‚Ä¶  166.999  157.887  158.591   169.208
 102.16    123.413  154.404  195.232     650.326  730.478  820.934   921.773
 115.916   147.906  189.681  241.337     740.939  831.939  933.283  1045.05
 500.948   497.538  503.546  519.094     236.155  290.869  355.618   430.493
 509.347   508.938  517.963  536.543     276.65   334.405  402.208   480.151
 865.257   795.452  734.771  683.37   ‚Ä¶  139.153  126.791  124.224   131.553
  94.9527  124.308  163.449  212.471     737.56   825.928  924.64   1033.77
 116.789   137.469  167.891  208.157     687.106  766.7    856.602   956.892
   ‚ãÆ                                  ‚ã±                             
 824.519   754.634  693.886  642.431     138.625  126.214  123.611   130.914
 249.207   202.414  165.122  137.46      517.414  528.978  550.657   582.531
 101.427   127.428  163.202  208.846  ‚Ä¶  728.035  813.02   908.339  1014.07
 572.532   563.767  564.398  574.551     279.304  328.614  387.943   457.382
 520.289   513.576  516.278  528.519     271.71   323.118  384.56    456.128
 666.184   569.611  482.304  404.414     537.561  498.793  469.946   451.108
 137.324   168.15   208.738  259.187     702.991  792.773  892.881  1003.39
 663.076   572.22   490.677  418.597  ‚Ä¶  642.398  609.461  586.486   573.557
 278.896   232.346  195.31   167.917     584.434  596.273  618.238   650.408
 114.491   142.244  179.758  227.129     690.446  777.151  874.178   981.605
 130.429   159.524  198.393  247.131     737.256  825.334  923.745  1032.57
 813.759   745.036  685.463  635.191     153.891  142.67   141.266   149.776</code></pre>
</div>
</div>
<p>In this next step, we need to be able to compute the probabilities <span class="math display">\begin{equation}
    p(\mathbf{t}_n\vert \mathbf{x}_k, W, \beta) \propto \exp\left(-\frac{\beta}{2}\lVert \mathbf{y}(\mathbf{x}_k,W) - \mathbf{t}_n \rVert^2 \right)
\end{equation}</span></p>
<p>when we use these probabilitieis to compute the responsabilities: <span class="math display">\begin{equation}
    r_{kn} = \frac{p(\mathbf{t}_n\vert \mathbf{x}_k, W, \beta)}{\sum_{k'}p(\mathbf{t}_n \vert \mathbf{x}_{k'}, W, \beta)}
\end{equation}</span> we can run into numerical overflow (i.e.&nbsp;exponentiating large numbers can easily blow up to larger than we can represent with a <code>Float64</code>). To avoid this trick, we take advantage of <a href="https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/">this cool trick</a>: <span class="math display">\begin{equation}
    \pi_i := \frac{\exp(x_i)}{\sum_j \exp(x_j)} = \frac{\exp(x_i-b)\exp(b))}{\sum_j\exp(x_j-b)\exp(b)} = \frac{\exp(x_i-b)}{\sum_j \exp(x_j-b)}.
\end{equation}</span> Choosing <span class="math inline">b=\max\{x_i\}_{i=1}^{n}</span> means well never exponentiate anything larger than <span class="math inline">0</span>!</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Update distribution `P`</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">Posterior</span>(Œ≤‚Åª¬π, D)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    inner <span class="op">=</span> <span class="op">-</span> D<span class="op">'</span> <span class="op">./</span> (<span class="fl">2</span><span class="op">*</span>Œ≤‚Åª¬π)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">exp</span>.(inner <span class="op">.-</span> <span class="fu">maximum</span>(inner))</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>Ptest <span class="op">=</span> <span class="fu">Posterior</span>(Œ≤‚Åª¬π, D)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>100√ó500 Matrix{Float64}:
 0.0336957   0.00470005  0.192516   ‚Ä¶  0.748761    0.676722    0.00884923
 0.0581538   0.00756072  0.273092      0.627834    0.562618    0.0136877
 0.0946067   0.0114799   0.364771      0.494816    0.439621    0.0199773
 0.144944    0.0164361   0.458395      0.366329    0.322655    0.0274855
 0.208926    0.0221626   0.541549      0.254654    0.222344    0.0356072
 0.283085    0.0281092   0.601127   ‚Ä¶  0.166207    0.143851    0.043383
 0.360304    0.033492    0.626766      0.101892    0.0874167   0.0496546
 0.430606    0.0374479   0.613933      0.0587312   0.0499489   0.0533403
 0.483254    0.0392629   0.565358      0.0318864   0.0268848   0.053748
 0.509604    0.0385909   0.490148      0.0163503   0.0136689   0.0507987
 0.0342877   0.00821162  0.178365   ‚Ä¶  0.787785    0.700696    0.0147263
 0.0592901   0.0132493   0.253306      0.660479    0.582446    0.0228413
 0.0965259   0.0201426   0.338457      0.520402    0.454975    0.0333754
 ‚ãÆ                                  ‚ã±                          
 0.106904    0.656263    0.0589926     0.0091741   0.00680563  0.608445
 0.11263     0.647508    0.0508977     0.00465121  0.00342018  0.576628
 0.00471022  0.0848936   0.0115907  ‚Ä¶  0.141768    0.110969    0.103196
 0.00818107  0.138307    0.0164701     0.118221    0.0917197   0.161441
 0.0133375   0.210938    0.022007      0.0929473   0.0714841   0.236556
 0.02043     0.301801    0.0276587     0.0688514   0.0524964   0.325273
 0.0294177   0.405663    0.0326933     0.0480038   0.0362871   0.420245
 0.0398223   0.512674    0.0363277  ‚Ä¶  0.0314607   0.0235778   0.510481
 0.0506634   0.609344    0.0379195     0.0193553   0.0143805   0.583097
 0.0605463   0.680999    0.0371521     0.0111637   0.00822244  0.626139
 0.0679258   0.715289    0.0341406     0.00603071  0.00440295  0.631744
 0.071499    0.70566     0.0294105     0.00304972  0.00220695  0.598529</code></pre>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(Ptest, dims<span class="op">=</span><span class="fl">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>1√ó500 Matrix{Float64}:
 16.6721  20.8193  23.1625  22.1693  ‚Ä¶  24.228  20.3408  17.1458  22.7755</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Update responsabilities R</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">Responsabilities</span>(P)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># sum along rows since each column is a new data point</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    Œ£s <span class="op">=</span> <span class="fu">sum</span>(P, dims<span class="op">=</span><span class="fl">1</span>)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    R <span class="op">=</span> P</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="op">‚àà</span> <span class="fu">axes</span>(R,<span class="fl">2</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>        R[<span class="op">:</span>,j] <span class="op">.=</span> (R[<span class="op">:</span>,j] <span class="op">./</span> Œ£s[j])</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> R</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>testR <span class="op">=</span> <span class="fu">Responsabilities</span>(Ptest)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>100√ó500 Matrix{Float64}:
 0.00202108   0.000225755  0.00831154   ‚Ä¶  0.0394686    0.000388541
 0.00348809   0.000363159  0.0117903       0.0328137    0.000600981
 0.00567455   0.000551408  0.0157483       0.0256401    0.000877137
 0.00869378   0.000789462  0.0197903       0.0188183    0.0012068
 0.0125315    0.00106452   0.0233804       0.0129678    0.00156339
 0.0169796    0.00135015   0.0259526    ‚Ä¶  0.00838987   0.00190481
 0.0216112    0.0016087    0.0270595       0.00509842   0.00218017
 0.0258279    0.00179871   0.0265054       0.00291318   0.002342
 0.0289858    0.00188589   0.0244083       0.00156801   0.0023599
 0.0305663    0.00185361   0.0211612       0.000797212  0.00223041
 0.00205659   0.000394423  0.00770059   ‚Ä¶  0.0408669    0.000646584
 0.00355625   0.000636395  0.010936        0.0339701    0.00100289
 0.00578967   0.000967498  0.0146123       0.0265356    0.0014654
 ‚ãÆ                                      ‚ã±               
 0.00641213   0.0315219    0.0025469       0.000396926  0.0267148
 0.0067556    0.0311013    0.00219742      0.000199476  0.0253178
 0.000282521  0.00407764   0.000500406  ‚Ä¶  0.00647208   0.00453102
 0.000490704  0.00664321   0.000711067     0.00534938   0.00708834
 0.00079999   0.0101318    0.000950111     0.00416918   0.0103864
 0.0012254    0.0144962    0.00119411      0.00306176   0.0142817
 0.00176449   0.0194849    0.00141147      0.00211638   0.0184516
 0.00238856   0.024625     0.00156838   ‚Ä¶  0.00137513   0.0224136
 0.00303881   0.0292682    0.00163711      0.000838718  0.0256019
 0.00363159   0.03271      0.00160397      0.000479559  0.0274917
 0.00407422   0.034357     0.00147396      0.000256794  0.0277378
 0.00428854   0.0338945    0.00126975      0.000128716  0.0262794</code></pre>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="fu">sum</span>(testR[<span class="op">:</span>,<span class="fl">1</span>]))</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="fu">scatter</span>(X[<span class="op">:</span>,<span class="fl">1</span>], X[<span class="op">:</span>,<span class="fl">2</span>],</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    zcolor<span class="op">=</span>testR[<span class="op">:</span>,<span class="fl">1</span>],</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">""</span>,</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>    xlabel<span class="op">=</span><span class="st">"x‚ÇÅ"</span>,</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    ylabel<span class="op">=</span><span class="st">"x‚ÇÇ"</span>,</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span><span class="st">"Responsability matrix for first data point"</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9999999999999999</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="21">
<p><img src="generative_topographic_mapping_files/figure-html/cell-22-output-2.svg" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>Œ£s <span class="op">=</span> <span class="fu">sum</span>(testR, dims<span class="op">=</span><span class="fl">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>100√ó1 Matrix{Float64}:
 5.270988586108698
 5.203487543373579
 5.159892266167381
 5.19336128556256
 5.319755065033108
 5.513619817151002
 5.716815257119075
 5.855947301654589
 5.862742798211288
 5.691700866974154
 5.484404832180334
 5.384138243422857
 5.298448885604486
 ‚ãÆ
 4.553882482951323
 4.2438179154570355
 3.706214494565581
 4.0302129678379375
 4.279109557883407
 4.462821610105696
 4.592327324580734
 4.669781298038044
 4.682743830970214
 4.60608261326271
 4.411794455081603
 4.082992869010511</code></pre>
</div>
</div>
<p>While the GTM model is not yet fit, we can clearly see the nice smoothness properties of the GTM activations for each latent node at play.</p>
<p>Next we need to construct a function for generating the diagonal matrix <code>G</code> from our responsabilities.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Update diagonal matrix `G`</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">GetGMatrix</span>(R)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># G is determined by the sum over data points at each node</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>    Œ£s <span class="op">=</span> <span class="fu">vec</span>(<span class="fu">sum</span>(R, dims<span class="op">=</span><span class="fl">2</span>))</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fu">diagm</span>(Œ£s)</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>testG <span class="op">=</span> <span class="fu">GetGMatrix</span>(testR)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>100√ó100 Matrix{Float64}:
 5.27099  0.0      0.0      0.0      ‚Ä¶  0.0      0.0      0.0      0.0
 0.0      5.20349  0.0      0.0         0.0      0.0      0.0      0.0
 0.0      0.0      5.15989  0.0         0.0      0.0      0.0      0.0
 0.0      0.0      0.0      5.19336     0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0         0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0      ‚Ä¶  0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0         0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0         0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0         0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0         0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0      ‚Ä¶  0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0         0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0         0.0      0.0      0.0      0.0
 ‚ãÆ                                   ‚ã±                             
 0.0      0.0      0.0      0.0         0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0         0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0      ‚Ä¶  0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0         0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0         0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0         0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0         0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0      ‚Ä¶  0.0      0.0      0.0      0.0
 0.0      0.0      0.0      0.0         4.68274  0.0      0.0      0.0
 0.0      0.0      0.0      0.0         0.0      4.60608  0.0      0.0
 0.0      0.0      0.0      0.0         0.0      0.0      4.41179  0.0
 0.0      0.0      0.0      0.0         0.0      0.0      0.0      4.08299</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="fu">size</span>(Œ¶))</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="fu">size</span>(testG))</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>Œ¶<span class="ch">'*testG*Œ¶</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(100, 26)
(100, 100)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>26√ó26 Matrix{Float64}:
 449.469  456.127  458.351  456.077  ‚Ä¶  455.883  453.619  446.946  473.745
 456.127  462.958  465.29   463.055     462.783  460.558  453.856  480.916
 458.351  465.29   467.708  465.535     465.187  463.024  456.358  483.415
 456.077  463.055  465.535  463.447     463.024  460.945  454.381  481.17
 449.369  456.317  458.835  456.849     456.358  454.381  447.983  474.245
 455.538  462.286  464.54   462.234  ‚Ä¶  462.332  460.036  453.268  480.29
 462.286  469.209  471.572  469.306     469.329  467.073  460.275  487.559
 464.54   471.572  474.023  471.82      471.767  469.573  462.813  490.093
 462.234  469.306  471.82   469.703     469.573  467.464  460.808  487.816
 455.436  462.478  465.029  463.016     462.813  460.808  454.318  480.795
 457.168  463.94   466.202  463.887  ‚Ä¶  464.281  461.975  455.179  482.157
 463.94   470.887  473.259  470.984     471.307  469.041  462.214  489.454
 466.202  473.259  475.718  473.507     473.755  471.552  464.763  491.997
 463.887  470.984  473.507  471.381     471.552  469.433  462.748  489.711
 457.064  464.131  466.691  464.67      464.763  462.748  456.231  482.663
 454.311  461.04   463.288  460.987  ‚Ä¶  461.673  459.379  452.621  479.292
 461.04   467.944  470.3    468.039     468.659  466.405  459.617  486.545
 463.288  470.3    472.743  470.546     471.093  468.902  462.15   489.073
 460.987  468.039  470.546  468.433     468.902  466.795  460.147  486.8
 454.207  461.228  463.772  461.763     462.15   460.147  453.666  479.793
 447.05   453.672  455.883  453.619  ‚Ä¶  454.584  452.325  445.67   471.779
 453.672  460.465  462.783  460.558     461.463  459.243  452.559  478.918
 455.883  462.783  465.187  463.024     463.859  461.701  455.053  481.406
 453.619  460.558  463.024  460.945     461.701  459.626  453.08   479.168
 446.946  453.856  456.358  454.381     455.053  453.08   446.698  472.271
 473.745  480.916  483.415  481.17   ‚Ä¶  481.406  479.168  472.271  500.0</code></pre>
</div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="fu">size</span>(Œ¶<span class="ch">'))</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="fu">size</span>(testR))</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="fu">size</span>(ùíü))</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>Œ¶<span class="ch">'*testR * ùíü</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(26, 100)
(100, 500)
(500, 10)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>26√ó10 Matrix{Float64}:
 -261.59   1077.55  753.524  -1589.33  ‚Ä¶   -992.69   719.924  589.339
 -273.021  1082.81  791.65   -1607.99     -1006.69   715.984  604.58
 -281.953  1077.34  822.58   -1610.93     -1010.88   704.807  614.087
 -288.123  1061.29  845.404  -1598.08     -1005.14   686.724  617.579
 -291.349  1035.14  859.447  -1569.8       -989.633  662.267  614.953
 -281.118  1100.49  756.758  -1597.38  ‚Ä¶  -1008.48   728.386  605.618
 -292.918  1105.95  795.27   -1616.02     -1022.76   724.417  621.211
 -302.027  1100.44  826.558  -1618.87     -1027.07   713.127  630.911
 -308.176  1084.13  849.701  -1605.84     -1021.3    694.849  634.431
 -311.186  1057.51  864.013  -1577.32     -1005.59   670.121  631.667
 -298.216  1112.87  752.498  -1589.6   ‚Ä¶  -1014.5    729.723  616.154
 -310.273  1118.47  791.018  -1608.03     -1028.92   725.765  631.951
 -319.471  1112.99  822.358  -1610.75     -1033.32   714.472  641.749
 -325.539  1096.58  845.594  -1597.67     -1027.56   696.178  645.263
 -328.297  1069.73  860.038  -1569.18     -1011.82   671.422  642.385
 -312.379  1114.33  740.869  -1566.2   ‚Ä¶  -1010.56   723.895  620.637
 -324.575  1120.02  779.021  -1584.25     -1024.99   719.987  636.481
 -333.772  1114.61  810.105  -1586.81     -1029.43   708.803  646.284
 -339.698  1098.26  833.205  -1573.81     -1023.75   690.672  649.755
 -342.177  1071.45  847.639  -1545.63     -1008.12   666.131  646.793
 -323.188  1104.82  722.215  -1527.89  ‚Ä¶   -996.802  711.074  618.934
 -335.402  1110.54  759.63   -1545.38     -1011.08   707.253  634.67
 -344.507  1105.25  790.158  -1547.76     -1015.52   696.285  644.379
 -350.235  1089.12  812.899  -1534.97     -1009.97   678.494  647.776
 -352.417  1062.61  827.18   -1507.37      -994.61   654.404  644.759
 -324.512  1131.0   834.937  -1637.2   ‚Ä¶  -1050.02   726.565  652.542</code></pre>
</div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Update parameter matrix W</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="co"># default regularization parameter to 0.0 unless otherwise specified</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="co"># regularization term is Œ±Œ≤‚Åª¬πI. </span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">UpdateW</span>(R, Œ¶, G, ùíü, Œ≤‚Åª¬π; Œ±<span class="op">=</span><span class="fl">0.0</span>)</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>    LHS <span class="op">=</span> Œ¶<span class="ch">'*G*Œ¶</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> Œ± <span class="op">&gt;</span> <span class="fl">0</span> </span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>        LHS <span class="op">.=</span> LHS <span class="op">+</span>  Œ±<span class="op">*</span>Œ≤‚Åª¬π<span class="op">*</span>I</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># now we have (LHS)W =  Œ¶'Rùíü</span></span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>    W_new <span class="op">=</span> <span class="fu">LHS\</span>(Œ¶<span class="ch">'*R*ùíü)</span></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> W_new<span class="op">'</span></span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>W1 <span class="op">=</span> <span class="fu">UpdateW</span>(testR, Œ¶, testG, ùíü, Œ≤‚Åª¬π)</span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a><span class="co">#W2 = UpdateW(testR, Œ¶, testG, ùíü, Œ≤‚Åª¬π; Œ±=0.5)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>10√ó26 adjoint(::Matrix{Float64}) with eltype Float64:
     -2.20266e5   -3.12138e5       5.45597e5  ‚Ä¶      -4.9478e5   -260.308
 -42985.6        -84.3087          3.06742e5          3.66509e5   231.078
      2.65987e5    4.24504e5      -1.20506e6         -4.50353e5  -182.856
     -7.27478e5   -5.50346e5       2.29158e6     -30563.0         700.014
 931010.0          9.52137e5      -2.90023e6          4.07587e5  -403.777
 -72194.0          3.81287e5  274640.0        ‚Ä¶       5.81112e5   837.586
     -4.48883e5   -4.50589e5       1.49966e6      18804.5         305.99
      5.74648e5    5.05304e5      -1.75306e6     236804.0        -337.267
     -4.4513e5    -5.36939e5       1.50089e6     -72687.3         118.802
     -1.93793e5   -2.08182e5       6.75236e5      66276.1         198.182</code></pre>
</div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>ND <span class="op">=</span> <span class="fu">size</span>(testR,<span class="fl">1</span>) <span class="op">*</span> <span class="fu">size</span>(testR,<span class="fl">2</span>)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>newbetainv <span class="op">=</span> <span class="fu">sum</span>(testR<span class="op">*</span>D)<span class="op">/</span>ND</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>401.2427310705195</code></pre>
</div>
</div>
<p>Now let‚Äôs skip ahead a couple of steps since the next two are just recalculating <code>Y</code> and <code>D</code></p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. Update Œ≤‚Åª¬π</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">UpdateBeta</span>(R, D)</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>    ND <span class="op">=</span> <span class="fu">size</span>(R,<span class="fl">1</span>)<span class="fu">*size</span>(R,<span class="fl">2</span>)</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fu">sum</span>(R<span class="op">*</span>D)<span class="op">/</span>ND</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a><span class="fu">UpdateBeta</span>(testR, D)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>401.2427310705195</code></pre>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>n_nodes <span class="op">=</span> <span class="fu">size</span>(Ptest,<span class="fl">1</span>)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>n_datapoints <span class="op">=</span> <span class="fu">size</span>(Ptest, <span class="fl">2</span>)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>n_dimensions <span class="op">=</span> <span class="fu">size</span>(ùíü, <span class="fl">2</span>)  <span class="co"># number of columns for each data record</span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(n_nodes)</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(n_datapoints)</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(n_dimensions)</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>loglikelihood <span class="op">=</span> <span class="fl">0.0</span> </span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>prior <span class="op">=</span> <span class="fl">1.0</span><span class="op">/</span>n_nodes</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a><span class="co"># now we need the exponential prefactor that we skipped before when calculating P matrix</span></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>prefactor <span class="op">=</span> (<span class="fl">1</span><span class="op">/</span>(<span class="fl">2</span><span class="op">*</span><span class="cn">œÄ</span><span class="op">*</span>Œ≤‚Åª¬π))<span class="op">^</span>(n_dimensions<span class="op">/</span><span class="fl">2</span>)</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a><span class="fu">-sum</span>(<span class="fu">log</span>.(prior <span class="op">.*</span> prefactor <span class="op">.*</span> Ptest))  <span class="co"># we want to maximize log-likelihood or minimize -log-likelihood</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>100
500
10</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>2.037922385452767e6</code></pre>
</div>
</div>
<p>The last piece we need is the ability to estimate the log-likelihood function‚Ä¶</p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">estimateLogLikelihood</span>(P, Œ≤‚Åª¬π, ùíü)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>    n_nodes <span class="op">=</span> <span class="fu">size</span>(Ptest,<span class="fl">1</span>)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>    n_datapoints <span class="op">=</span> <span class="fu">size</span>(Ptest, <span class="fl">2</span>)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>    n_dimensions <span class="op">=</span> <span class="fu">size</span>(ùíü, <span class="fl">2</span>)  <span class="co"># number of columns for each data record</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>    prior <span class="op">=</span> <span class="fl">1.0</span><span class="op">/</span>n_nodes</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># now we need the exponential prefactor that we skipped before when calculating P matrix</span></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>    prefactor <span class="op">=</span> (<span class="fl">1</span><span class="op">/</span>(<span class="fl">2</span><span class="op">*</span><span class="cn">œÄ</span><span class="op">*</span>Œ≤‚Åª¬π))<span class="op">^</span>(n_dimensions<span class="op">/</span><span class="fl">2</span>)</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a>    loglikelihood <span class="op">=</span> <span class="fu">sum</span>(<span class="fu">log</span>.(prior <span class="op">.*</span> prefactor <span class="op">.*</span> Ptest))<span class="op">./</span>n_datapoints  <span class="co"># we want to maximize log-likelihood or minimize -log-likelihood</span></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loglikelihood</span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a>ll <span class="op">=</span> <span class="fu">estimateLogLikelihood</span>(Ptest, Œ≤‚Åª¬π, ùíü)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>-4075.844770905534</code></pre>
</div>
</div>
<p>supposing we have fit our model and now have the final responsability matrix, we will then need the ability to visualize the results! Recall that we have two <em>nice</em> ways to do this:</p>
<ol type="1">
<li>With the mean <span class="math inline">\langle \mathbf{x} \vert \mathbf{t}_n, W, \beta \rangle = \sum_k^K R_{kn}\mathbf{x}_k</span></li>
<li>With the mode <span class="math inline">\mathbf{x}_{\text{mode}} = \mathbf{x}_{k^\text{max}}</span> where <span class="math inline">k^{\text{max}} = \underset{\{k\}}{\text{argmax}} R_{kn}</span></li>
</ol>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="fu">size</span>(testR))</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="fu">size</span>(X))</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> testR<span class="op">'</span> <span class="op">*</span> X</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>cpalette <span class="op">=</span> <span class="fu">cgrad</span>(<span class="op">:</span>Accent_5, <span class="fl">5</span>, categorical<span class="op">=</span><span class="cn">true</span>)</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>p1 <span class="op">=</span> <span class="fu">scatter</span>(res[<span class="op">:</span>,<span class="fl">1</span>], res[<span class="op">:</span>,<span class="fl">2</span>], marker_z<span class="op">=</span><span class="fu">int</span>(Datay), color<span class="op">=</span>cpalette, label<span class="op">=</span><span class="st">""</span>, colorbar<span class="op">=</span><span class="cn">false</span>, title<span class="op">=</span><span class="st">"PCA Initialization (mean)"</span>) </span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>p2 <span class="op">=</span> <span class="fu">scatter</span>(ùíü[<span class="op">:</span>,<span class="fl">1</span>],ùíü[<span class="op">:</span>,<span class="fl">2</span>], marker_z<span class="op">=</span><span class="fu">int</span>(Datay), color<span class="op">=</span>cpalette, label<span class="op">=</span><span class="st">""</span>, colorbar<span class="op">=</span><span class="cn">false</span>, title<span class="op">=</span><span class="st">"Original"</span>)</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p2, p1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(100, 500)
(100, 2)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="53">
<p><img src="generative_topographic_mapping_files/figure-html/cell-32-output-2.svg" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># nodex √ó datapoints</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="fu">size</span>(testR))</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="fu">argmax</span>(testR[<span class="op">:</span>,<span class="fl">1</span>])</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="fu">scatter</span>(X[<span class="op">:</span>,<span class="fl">1</span>], X[<span class="op">:</span>,<span class="fl">2</span>], marker_z<span class="op">=</span>testR[<span class="op">:</span>,<span class="fl">5</span>])</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(100, 500)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="54">
<p><img src="generative_topographic_mapping_files/figure-html/cell-33-output-2.svg" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> <span class="fu">argmax</span>(testR, dims<span class="op">=</span><span class="fl">1</span>)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> [idx[i][<span class="fl">1</span>] for i <span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(idx)]</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> X[idx, <span class="op">:</span>]</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a><span class="co"># p3 = scatter(res[:,1], res[:,2], marker_z=int(Datay), color=cpalette, label="", colorbar=false, title="PCA Initialization (mode)")</span></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a><span class="co"># plot(p2, p1, p3, layout=(1,3), size=(1200, 300))</span></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a><span class="fu">scatter!</span>(p1, res[<span class="op">:</span>,<span class="fl">1</span>], res[<span class="op">:</span>,<span class="fl">2</span>], marker_z<span class="op">=</span><span class="fu">int</span>(Datay), color<span class="op">=</span>cpalette, marker<span class="op">=:</span>square, label<span class="op">=</span><span class="st">""</span>, colorbar<span class="op">=</span><span class="cn">false</span>, title<span class="op">=</span><span class="st">"PCA Initialization (mode)"</span>)</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p2, p1, size<span class="op">=</span>(<span class="fl">800</span>, <span class="fl">300</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<p><img src="generative_topographic_mapping_files/figure-html/cell-34-output-1.svg" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">get_means</span>(R, X)</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> R<span class="op">'</span> <span class="op">*</span> X</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">get_modes</span>(R, X)</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> <span class="fu">argmax</span>(R, dims<span class="op">=</span><span class="fl">1</span>)</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> [idx[i][<span class="fl">1</span>] for i <span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(idx)]</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X[idx, <span class="op">:</span>]</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a><span class="fu">println</span>(<span class="fu">size</span>(testR))</span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a><span class="fu">get_means</span>(testR, X);</span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a><span class="fu">get_modes</span>(testR, X);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(100, 500)</code></pre>
</div>
</div>
<p>We now have all of the pieces we need to be able to perform the EM algorithm until our model has converged. Let‚Äôs try it out!:</p>
<p>Summary of all steps:</p>
<ol type="1">
<li>Initialize GTM grid parameters: number of nodes = k<em>k, number of rbf centers = m</em>m</li>
<li>Create node matrix <span class="math inline">X</span> (holding coordinates)</li>
<li>Create rbf centers matrix M</li>
<li>Initialize rbf width <span class="math inline">\sigma</span></li>
<li>Create rbf matrix <span class="math inline">\Phi</span></li>
<li>Perform PCA on the data</li>
<li>Set U matrix to 2 first principal axes of data cov. matrix (result of PCA)</li>
<li>Initialize parameter matrix W using U and <span class="math inline">\Phi</span></li>
<li>Initialize manifold Y using W and <span class="math inline">\Phi</span></li>
<li>Set noise variance parameter <span class="math inline">\beta^{-1}</span> to the largest between:
<ol type="1">
<li>the 3rd eigenvalue of the data covariance matrix (i.e.&nbsp;3d explained variance value)</li>
<li>half the average distance between centers of Gaussian components</li>
</ol></li>
<li>Create distance matrix D between manifold and data matrix</li>
<li>Repeat until convergence
<ol type="1">
<li>Update data distribution P</li>
<li>Update responsibilities R</li>
<li>Update diagonal matrix G</li>
<li>Update parameter matrix W</li>
<li>Update manifold matrix Y</li>
<li>Update distance matrix D</li>
<li>Update noise variance parameter <span class="math inline">\beta^{-1}</span></li>
<li>Estimate log likelihood and check for convergence</li>
</ol></li>
<li>Compute 2D GTM representation 1: means</li>
<li>Compute 2D GTM representation 2: modes</li>
</ol>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">getCoordsMatrix</span>(k)</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="fu">range</span>(<span class="op">-</span><span class="fl">1.0</span>, <span class="fl">1.0</span>, length<span class="op">=</span>k) </span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>    xs <span class="op">=</span> <span class="fu">vcat</span>([x[i] for i <span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(x), j <span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(x)]<span class="op">...</span>)</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>    ys <span class="op">=</span> <span class="fu">vcat</span>([x[j] for i <span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(x), j<span class="op">‚àà</span> <span class="fl">1</span><span class="op">:</span><span class="fu">length</span>(x)]<span class="op">...</span>)</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> <span class="fu">hcat</span>(xs, ys)  <span class="co"># X[:,1] are the x positions, X[:,2] are the y positions</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>getCoordsMatrix (generic function with 1 method)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="kw">function</span> <span class="fu">getŒ¶Matrix</span>(X, M)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>    Œ¶ <span class="op">=</span> <span class="fu">zeros</span>(n_nodes, n_rbf_centers <span class="op">+</span> <span class="fl">1</span>)</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="op">‚àà</span> <span class="fu">axes</span>(M,<span class="fl">1</span>), <span class="fu">i‚ààaxes</span>(X,<span class="fl">1</span>)</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>        Œ¶[i,j] <span class="op">=</span> <span class="fu">exp</span>(<span class="fu">-sqeuclidean</span>(X[i,<span class="op">:</span>], M[j,<span class="op">:</span>])<span class="op">/</span>(<span class="fl">2</span>œÉ))</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set the last column to ones to allow for a bias term</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>    Œ¶[<span class="op">:</span>,<span class="kw">end</span>] <span class="op">.=</span> <span class="fl">1</span></span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Œ¶</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>getŒ¶Matrix (generic function with 1 method)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 0. load dataset</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">RDatasets</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> <span class="fu">dataset</span>(<span class="st">"datasets"</span>,<span class="st">"iris"</span>)</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>Dataset <span class="op">=</span><span class="fu">Matrix</span>(iris[<span class="op">:</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">4</span>])</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>classes <span class="op">=</span> iris[<span class="op">:</span>,<span class="fl">5</span>]</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Initialize GTM Parameters </span></span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="fl">20</span>  <span class="co"># there are K=k¬≤ total latent nodes</span></span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="fl">10</span>  <span class="co"># there are M=m¬≤ basis functions (centers of our RBFs) </span></span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a>œÉ <span class="op">=</span> <span class="fl">0.3</span> <span class="co"># the œÉ¬≤ is the variance in our RBFs</span></span>
<span id="cb72-14"><a href="#cb72-14" aria-hidden="true" tabindex="-1"></a>Œ±<span class="op">=</span><span class="fl">0.1</span> <span class="co"># reglarization parameter</span></span>
<span id="cb72-15"><a href="#cb72-15" aria-hidden="true" tabindex="-1"></a>tol <span class="op">=</span> <span class="fl">0.0001</span> <span class="co">#  stop fitting if difference in log-likelihood is less than this amount</span></span>
<span id="cb72-16"><a href="#cb72-16" aria-hidden="true" tabindex="-1"></a>verbose <span class="op">=</span> <span class="cn">true</span></span>
<span id="cb72-17"><a href="#cb72-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-18"><a href="#cb72-18" aria-hidden="true" tabindex="-1"></a>n_nodes <span class="op">=</span> k<span class="op">*</span>k </span>
<span id="cb72-19"><a href="#cb72-19" aria-hidden="true" tabindex="-1"></a>n_rbf_centers <span class="op">=</span> m<span class="op">*</span>m </span>
<span id="cb72-20"><a href="#cb72-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-21"><a href="#cb72-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-22"><a href="#cb72-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. create node matrix `X`</span></span>
<span id="cb72-23"><a href="#cb72-23" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> <span class="fu">getCoordsMatrix</span>(k)</span>
<span id="cb72-24"><a href="#cb72-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-25"><a href="#cb72-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. create RBF centers matrix `M`</span></span>
<span id="cb72-26"><a href="#cb72-26" aria-hidden="true" tabindex="-1"></a>M <span class="op">=</span> <span class="fu">getCoordsMatrix</span>(m)</span>
<span id="cb72-27"><a href="#cb72-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-28"><a href="#cb72-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Initialize RBF variance `œÉ`</span></span>
<span id="cb72-29"><a href="#cb72-29" aria-hidden="true" tabindex="-1"></a>œÉ <span class="op">=</span> <span class="fu">mean</span>(<span class="fu">sqeuclidean</span>(M[<span class="op">:</span>,<span class="fl">1</span>], M[<span class="op">:</span>,<span class="fl">2</span>]))  <span class="co"># sqeuclidean is Squared Euclidean distance</span></span>
<span id="cb72-30"><a href="#cb72-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-31"><a href="#cb72-31" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Create RBF matrix `Œ¶`</span></span>
<span id="cb72-32"><a href="#cb72-32" aria-hidden="true" tabindex="-1"></a>Œ¶ <span class="op">=</span> <span class="fu">getŒ¶Matrix</span>(X,M)</span>
<span id="cb72-33"><a href="#cb72-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-34"><a href="#cb72-34" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Perform PCA on Data </span></span>
<span id="cb72-35"><a href="#cb72-35" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> <span class="fu">fit</span>(PCA, Dataset<span class="op">'</span>; maxoutdim<span class="op">=</span><span class="fl">3</span>)</span>
<span id="cb72-36"><a href="#cb72-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-37"><a href="#cb72-37" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. Set U to first two columns of data covariance matrix</span></span>
<span id="cb72-38"><a href="#cb72-38" aria-hidden="true" tabindex="-1"></a>pca_vecs <span class="op">=</span> <span class="fu">projection</span>(pca)  <span class="co"># this results the princiap component vectors (columns) sorted in order of explained variance </span></span>
<span id="cb72-39"><a href="#cb72-39" aria-hidden="true" tabindex="-1"></a>pca_var <span class="op">=</span> <span class="fu">principalvars</span>(pca)</span>
<span id="cb72-40"><a href="#cb72-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-41"><a href="#cb72-41" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> pca_vecs[<span class="op">:</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">2</span>] </span>
<span id="cb72-42"><a href="#cb72-42" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="op">‚àà</span> <span class="fu">axes</span>(U,<span class="fl">2</span>)</span>
<span id="cb72-43"><a href="#cb72-43" aria-hidden="true" tabindex="-1"></a>    U[<span class="op">:</span>,i] <span class="op">.=</span> <span class="fu">sqrt</span>(pca_var[i])<span class="op">.*</span>U[<span class="op">:</span>,i] </span>
<span id="cb72-44"><a href="#cb72-44" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb72-45"><a href="#cb72-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-46"><a href="#cb72-46" aria-hidden="true" tabindex="-1"></a><span class="co"># 8. Initialize parameter matrix `W` </span></span>
<span id="cb72-47"><a href="#cb72-47" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> <span class="fu">Init_W_Matrix</span>(X, Œ¶, U)</span>
<span id="cb72-48"><a href="#cb72-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-49"><a href="#cb72-49" aria-hidden="true" tabindex="-1"></a><span class="co"># 9. Initialize projection manifold `Y`</span></span>
<span id="cb72-50"><a href="#cb72-50" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> W<span class="op">*</span>Œ¶<span class="ch">'</span></span>
<span id="cb72-51"><a href="#cb72-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-52"><a href="#cb72-52" aria-hidden="true" tabindex="-1"></a><span class="co"># 10. Initialize covariance `Œ≤‚Åª¬π`</span></span>
<span id="cb72-53"><a href="#cb72-53" aria-hidden="true" tabindex="-1"></a>Œ≤‚Åª¬π <span class="op">=</span> <span class="fu">maximum</span>([<span class="fu">mean</span>(<span class="fu">pairwise</span>(sqeuclidean, Y, dims<span class="op">=</span><span class="fl">2</span>))<span class="op">/</span><span class="fl">2</span>, pca_var[<span class="kw">end</span>]])</span>
<span id="cb72-54"><a href="#cb72-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-55"><a href="#cb72-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-56"><a href="#cb72-56" aria-hidden="true" tabindex="-1"></a><span class="co"># 11. Create distance matrix `D` </span></span>
<span id="cb72-57"><a href="#cb72-57" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> <span class="fu">pairwise</span>(sqeuclidean, Y, Dataset<span class="op">'</span>)<span class="ch">'</span></span>
<span id="cb72-58"><a href="#cb72-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-59"><a href="#cb72-59" aria-hidden="true" tabindex="-1"></a><span class="co"># 12. Repeat unitl convergence </span></span>
<span id="cb72-60"><a href="#cb72-60" aria-hidden="true" tabindex="-1"></a><span class="co"># niter = 1000  # default maximum number of iterations</span></span>
<span id="cb72-61"><a href="#cb72-61" aria-hidden="true" tabindex="-1"></a>niter <span class="op">=</span> <span class="fl">20</span>  <span class="co"># default maximum number of iterations</span></span>
<span id="cb72-62"><a href="#cb72-62" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> <span class="fl">1</span>  </span>
<span id="cb72-63"><a href="#cb72-63" aria-hidden="true" tabindex="-1"></a>diff <span class="op">=</span> <span class="fl">1000</span></span>
<span id="cb72-64"><a href="#cb72-64" aria-hidden="true" tabindex="-1"></a>converged <span class="op">=</span><span class="fl">0</span></span>
<span id="cb72-65"><a href="#cb72-65" aria-hidden="true" tabindex="-1"></a>minus‚Ñì <span class="op">=</span> <span class="fl">1000</span></span>
<span id="cb72-66"><a href="#cb72-66" aria-hidden="true" tabindex="-1"></a>minus‚Ñì_prev <span class="op">=</span> <span class="fl">1000</span> </span>
<span id="cb72-67"><a href="#cb72-67" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> i <span class="op">&lt;</span> (niter) <span class="op">&amp;&amp;</span> converged <span class="op">&lt;</span> <span class="fl">4</span></span>
<span id="cb72-68"><a href="#cb72-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-69"><a href="#cb72-69" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. update data distribution</span></span>
<span id="cb72-70"><a href="#cb72-70" aria-hidden="true" tabindex="-1"></a>    Pmat <span class="op">=</span> <span class="fu">Posterior</span>(Œ≤‚Åª¬π, D)</span>
<span id="cb72-71"><a href="#cb72-71" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-72"><a href="#cb72-72" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. compute responsabilities</span></span>
<span id="cb72-73"><a href="#cb72-73" aria-hidden="true" tabindex="-1"></a>    R <span class="op">=</span> <span class="fu">Responsabilities</span>(Pmat)</span>
<span id="cb72-74"><a href="#cb72-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-75"><a href="#cb72-75" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Update diagonal matrix `G`</span></span>
<span id="cb72-76"><a href="#cb72-76" aria-hidden="true" tabindex="-1"></a>    G <span class="op">=</span> <span class="fu">GetGMatrix</span>(R)</span>
<span id="cb72-77"><a href="#cb72-77" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-78"><a href="#cb72-78" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Update parameter matrix `W`</span></span>
<span id="cb72-79"><a href="#cb72-79" aria-hidden="true" tabindex="-1"></a>    W <span class="op">=</span> <span class="fu">UpdateW</span>(R, Œ¶, G, Dataset, Œ≤‚Åª¬π; Œ±<span class="op">=</span>Œ±)</span>
<span id="cb72-80"><a href="#cb72-80" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-81"><a href="#cb72-81" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5. Update manifold matrix `Y`</span></span>
<span id="cb72-82"><a href="#cb72-82" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> W<span class="op">*</span>Œ¶<span class="ch">'</span></span>
<span id="cb72-83"><a href="#cb72-83" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb72-84"><a href="#cb72-84" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 6. Update distance matrix `D`</span></span>
<span id="cb72-85"><a href="#cb72-85" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> <span class="fu">pairwise</span>(sqeuclidean, Y, Dataset<span class="op">'</span>)<span class="ch">'</span></span>
<span id="cb72-86"><a href="#cb72-86" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-87"><a href="#cb72-87" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 7. Update `Œ≤‚Åª¬π`</span></span>
<span id="cb72-88"><a href="#cb72-88" aria-hidden="true" tabindex="-1"></a>    Œ≤‚Åª¬π <span class="op">=</span> <span class="fu">UpdateBeta</span>(R, D)</span>
<span id="cb72-89"><a href="#cb72-89" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-90"><a href="#cb72-90" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 8. Estimate log-likelihood and check for convergence</span></span>
<span id="cb72-91"><a href="#cb72-91" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">==</span> <span class="fl">1</span></span>
<span id="cb72-92"><a href="#cb72-92" aria-hidden="true" tabindex="-1"></a>        minus‚Ñì <span class="op">=</span> <span class="fu">-estimateLogLikelihood</span>(Pmat, Œ≤‚Åª¬π, Dataset)</span>
<span id="cb72-93"><a href="#cb72-93" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span></span>
<span id="cb72-94"><a href="#cb72-94" aria-hidden="true" tabindex="-1"></a>        minus‚Ñì_prev <span class="op">=</span> minus‚Ñì</span>
<span id="cb72-95"><a href="#cb72-95" aria-hidden="true" tabindex="-1"></a>        minus‚Ñì <span class="op">=</span> <span class="fu">-estimateLogLikelihood</span>(Pmat, Œ≤‚Åª¬π, Dataset)</span>
<span id="cb72-96"><a href="#cb72-96" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb72-97"><a href="#cb72-97" aria-hidden="true" tabindex="-1"></a>        diff <span class="op">=</span> <span class="fu">abs</span>(minus‚Ñì_prev <span class="op">-</span> minus‚Ñì)</span>
<span id="cb72-98"><a href="#cb72-98" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb72-99"><a href="#cb72-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-100"><a href="#cb72-100" aria-hidden="true" tabindex="-1"></a>    <span class="co"># we need to have 4 consecutaive updates with diff at or below the tolerance to exit</span></span>
<span id="cb72-101"><a href="#cb72-101" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> diff <span class="op">&lt;=</span> tol</span>
<span id="cb72-102"><a href="#cb72-102" aria-hidden="true" tabindex="-1"></a>        converged <span class="op">+=</span> <span class="fl">1</span></span>
<span id="cb72-103"><a href="#cb72-103" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span></span>
<span id="cb72-104"><a href="#cb72-104" aria-hidden="true" tabindex="-1"></a>        converged <span class="op">=</span> <span class="fl">0</span> </span>
<span id="cb72-105"><a href="#cb72-105" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb72-106"><a href="#cb72-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-107"><a href="#cb72-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose</span>
<span id="cb72-108"><a href="#cb72-108" aria-hidden="true" tabindex="-1"></a>        <span class="fu">println</span>(<span class="st">"Iter: "</span>, i, <span class="st">"  ‚Ñì: "</span>, <span class="op">-</span>minus‚Ñì)</span>
<span id="cb72-109"><a href="#cb72-109" aria-hidden="true" tabindex="-1"></a>    <span class="cf">end</span></span>
<span id="cb72-110"><a href="#cb72-110" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-111"><a href="#cb72-111" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-112"><a href="#cb72-112" aria-hidden="true" tabindex="-1"></a>    i <span class="op">+=</span> <span class="fl">1</span></span>
<span id="cb72-113"><a href="#cb72-113" aria-hidden="true" tabindex="-1"></a><span class="cf">end</span></span>
<span id="cb72-114"><a href="#cb72-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-115"><a href="#cb72-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-116"><a href="#cb72-116" aria-hidden="true" tabindex="-1"></a>Pmat <span class="op">=</span> <span class="fu">Posterior</span>(Œ≤‚Åª¬π, D);</span>
<span id="cb72-117"><a href="#cb72-117" aria-hidden="true" tabindex="-1"></a>R <span class="op">=</span> <span class="fu">Responsabilities</span>(Pmat);</span>
<span id="cb72-118"><a href="#cb72-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-119"><a href="#cb72-119" aria-hidden="true" tabindex="-1"></a><span class="co"># 13. Compute mean node responsability </span></span>
<span id="cb72-120"><a href="#cb72-120" aria-hidden="true" tabindex="-1"></a>Rmeans <span class="op">=</span> <span class="fu">get_means</span>(R, X);</span>
<span id="cb72-121"><a href="#cb72-121" aria-hidden="true" tabindex="-1"></a><span class="co"># 14. compute mode node responsability</span></span>
<span id="cb72-122"><a href="#cb72-122" aria-hidden="true" tabindex="-1"></a>Rmodes <span class="op">=</span> <span class="fu">get_modes</span>(R, X);</span>
<span id="cb72-123"><a href="#cb72-123" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Iter: 1  ‚Ñì: -1677.4983562758482
Iter: 2  ‚Ñì: -1645.0048054848849
Iter: 3  ‚Ñì: -1644.0327191330757
Iter: 4  ‚Ñì: -1643.8901319265444
Iter: 5  ‚Ñì: -1643.8685996044135
Iter: 6  ‚Ñì: -1643.8653369980282
Iter: 7  ‚Ñì: -1643.8648423917648
Iter: 8  ‚Ñì: -1643.8647674044073
Iter: 9  ‚Ñì: -1643.8647560354252
Iter: 10  ‚Ñì: -1643.8647543117486
Iter: 11  ‚Ñì: -1643.864754050418</code></pre>
</div>
</div>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Rmodes</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>R</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>400√ó150 Matrix{Float64}:
 0.00255425  0.00256575  0.00256974  ‚Ä¶  0.00245752  0.00245512  0.00247454
 0.00254577  0.00255542  0.00255877     0.00246429  0.00246227  0.00247867
 0.00253821  0.00254622  0.002549       0.00247029  0.0024686   0.00248231
 0.00253157  0.00253816  0.00254044     0.00247553  0.00247413  0.00248548
 0.00252587  0.00253125  0.00253311     0.00248001  0.00247886  0.00248817
 0.00252111  0.00252548  0.00252699  ‚Ä¶  0.00248374  0.0024828   0.0024904
 0.0025173   0.00252086  0.00252209     0.00248671  0.00248594  0.00249218
 0.00251444  0.0025174   0.00251842     0.00248894  0.0024883   0.00249351
 0.00251253  0.00251509  0.00251598     0.00249042  0.00248986  0.00249439
 0.00251159  0.00251394  0.00251476     0.00249116  0.00249064  0.00249483
 0.00251159  0.00251395  0.00251477  ‚Ä¶  0.00249116  0.00249064  0.00249482
 0.00251256  0.00251512  0.00251601     0.00249041  0.00248985  0.00249438
 0.00251448  0.00251744  0.00251847     0.00248891  0.00248827  0.00249349
 ‚ãÆ                                   ‚ã±                          
 0.00251254  0.0025151   0.00251599     0.00249042  0.00248986  0.00249439
 0.00251159  0.00251395  0.00251477     0.00249116  0.00249064  0.00249483
 0.0025116   0.00251396  0.00251478  ‚Ä¶  0.00249115  0.00249063  0.00249482
 0.00251257  0.00251513  0.00251601     0.0024904   0.00248984  0.00249437
 0.00251449  0.00251745  0.00251848     0.00248891  0.00248826  0.00249348
 0.00251736  0.00252093  0.00252216     0.00248667  0.0024859   0.00249215
 0.00252119  0.00252556  0.00252708     0.00248369  0.00248274  0.00249036
 0.00252597  0.00253134  0.00253321  ‚Ä¶  0.00247995  0.00247879  0.00248812
 0.00253168  0.00253828  0.00254057     0.00247546  0.00247405  0.00248542
 0.00253834  0.00254635  0.00254914     0.00247021  0.00246851  0.00248224
 0.00254592  0.00255557  0.00255893     0.00246419  0.00246216  0.00247859
 0.00255441  0.00256592  0.00256992     0.00245741  0.00245501  0.00247445</code></pre>
</div>
</div>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize! </span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>p1 <span class="op">=</span> <span class="fu">scatter</span>(Dataset[<span class="op">:</span>,<span class="fl">1</span>],Dataset[<span class="op">:</span>,<span class="fl">2</span>], marker_z<span class="op">=</span><span class="fu">int</span>(classes), color<span class="op">=:</span>Accent_3, label<span class="op">=</span><span class="st">""</span>, colorbar<span class="op">=</span><span class="cn">false</span>, title<span class="op">=</span><span class="st">"Original Data"</span>)</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>p2 <span class="op">=</span> <span class="fu">scatter</span>(Rmeans[<span class="op">:</span>,<span class="fl">1</span>], Rmeans[<span class="op">:</span>,<span class="fl">2</span>], marker_z<span class="op">=</span><span class="fu">int</span>(classes), color<span class="op">=:</span>Accent_3, label<span class="op">=</span><span class="st">""</span>, colorbar<span class="op">=</span><span class="cn">false</span>, title<span class="op">=</span><span class="st">"Mean node responsability"</span>) </span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>p3 <span class="op">=</span> <span class="fu">scatter</span>(Rmodes[<span class="op">:</span>,<span class="fl">1</span>], Rmodes[<span class="op">:</span>,<span class="fl">2</span>], marker_z<span class="op">=</span><span class="fu">int</span>(classes), color<span class="op">=:</span>Accent_3, label<span class="op">=</span><span class="st">""</span>, colorbar<span class="op">=</span><span class="cn">false</span>, title<span class="op">=</span><span class="st">"Mode node responsability"</span>)</span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p1, p2, p3, layout<span class="op">=</span>(<span class="fl">1</span>,<span class="fl">3</span>), size<span class="op">=</span>(<span class="fl">1200</span>, <span class="fl">300</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<p><img src="generative_topographic_mapping_files/figure-html/cell-40-output-1.svg" class="img-fluid"></p>
</div>
</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>